---
title: "TPAle IDM - BCRA"
lang: es
author: "Gomez Fernandez, Alejandro"
format: 
  html:
    grid: 
      sidebar-width: 350px
      body-width: 900px
      margin-width: 5px
    theme: 
      light: [lumen, ./resultados/reportes/ale.scss]
    toc: true
    toc-location: left
    toc-depth: 3
    code-fold: true
    output-dir: "./resultados/reportes"
embed-resources: true
page-layout: full
editor: 
  markdown: 
    wrap: 72
---

# Introduccion

Introducci√≥n a la Miner√≠a de Datos Trabajo Pr√°ctico Final 2 Universidad
Austral Maestr√≠a en Ciencia de Datos Introducci√≥n al Data Mining Trabajo
Pr√°ctico Final Fecha de entrega: 23/02/2025 1. Introducci√≥n ESTUDIO DE
LAS DEUDAS REGISTRADAS DEL SISTEMA FINANCIERO ARGENTINO El Banco Central
de la Rep√∫blica Argentina (BCRA) publica mensualmente un informe
consolidado de deudas actuales e hist√≥ricas (24 meses), denominado
'Central de Deudores del Sistema Financiero' elaborado en funci√≥n de los
datos recibidos de distintos tipos de entidades financieras (entidades
financieras, empresas no financieras emisoras de tarjetas, fideicomisos
financieros, otros proveedores no financieros de cr√©dito, etc.), las
cuales deben obligatoriamente remitir mensualmente al BCRA, detallando
la totalidad de las financiaciones con la correspondiente situaci√≥n de
cada deudor.

Cada deuda informada al BCRA es acompa√±ada de su situaci√≥n que es una
aproximaci√≥n a la cantidad de d√≠as de atraso en el cumplimiento de pago:

Situaci√≥n 1 \| Situaci√≥n normal: atraso en el pago que no supere los 31
d√≠as. Situaci√≥n 2 \| Riesgo bajo: atraso en el pago de m√°s de 31 d√≠as y
hasta 90 d√≠as. Situaci√≥n 3 \| Riesgo miedo: atraso en el pago de m√°s de
90 d√≠as y hasta 180 d√≠as. Situaci√≥n 4 \| Riesgo alto: atraso en el pago
de m√°s de 180 d√≠as a un a√±o. Situaci√≥n 5 \| Irrecuperable: atraso
superior a un a√±o. Situaci√≥n 6 \| Irrecuperable por disposici√≥n t√©cnica:
deuda con una ex entidad.

Se cuenta con una muestra aleatoria de 19.737 cuits de personas f√≠sicas
que ten√≠an al menos una de deuda en el sistema financiero en Junio de
2019, que se encontraban en situaci√≥n crediticia 1 o 2 (es decir, que no
tuvieran atrasos mayores a 90 d√≠as) y cuyo monto total adeudado en ese
momento no superaba los 100.000 pesos argentinos.

Para los cuits de la muestra aleatoria se registraron y resumieron las
deudas en todas las entidades en Junio de 2019 y tambi√©n 6 meses hacia
atr√°s. Tambi√©n se registraron las deudas de esos cuits entre Julio 2019
y Junio 2020 para poder evaluar su evoluci√≥n.

# Resoluci√≥n

## Inicializacion del entorno

```{r}

# Importar bibliotecas
knitr::opts_chunk$set(echo = TRUE)

listofpackages <- c("corrplot", "dplyr", "FactoMineR", "factoextra", 
                    "ggfortify", "ggplot2", "grid", "gridExtra", "gtExtras", 
                    "kableExtra", "knitr", "pastecs", "psych", "readr", "skimr",
                    "tidyverse")
# Cita de C√≥digo
# C√≥digo tomado de: https://github.com/lkovalevski/textsimilaritiesinR/tree/691b5798553d81a86b6c151557c4a667f8c58643/ejecutarAnalisisTexto.R
# Autor: lkovalevski
#
newPackages <- listofpackages[ !(listofpackages %in% installed.packages()[, "Package"])]
if(length(newPackages)) install.packages(newPackages)
for (paquete in listofpackages) {
  suppressMessages(library(paquete, character.only = TRUE))
}

```

## Carga y limpieza de datos

```{r}

# Abrimos el archivo que se encuentra en la carpeta datos_entrada
archivo_datos <- readRDS("./datos_entrada/df_bcra_individuals.rds")

# Describimos el dataset

skimr::skim(archivo_datos)
knitr::kable(str(archivo_datos))
knitr::kable(t(head(archivo_datos)))

# Vemos las columnas con datos nulos o faltantes
columnas_con_nulos <- archivo_datos %>%
  summarise(across(everything(), ~ sum(is.na(.)))) %>%
  pivot_longer(cols = everything(), names_to = "columna", values_to = "num_nulos") %>%
  filter(num_nulos > 0)

knitr::kable(columnas_con_nulos)


```

### Preprocesamiento de datos

```{r}


# Hacemos una copia del dataset para trabajar en el manteniendo el original

df_datos <- archivo_datos

# Nos aseguramos que las columnas num√©ricas solo contienen datos num√©ricos

df_datos <- df_datos %>%
    mutate(across(where(is.numeric), ~ as.numeric(as.character(.))))


# Nos aseguramos que las columnas especificadas sean de tipo categ√≥rico
df_datos <- df_datos %>%
    mutate(across(c(tipo_persona, n_deudas_actual, situacion_mes_actual, tiene_garantia_actual, 
                   max_situacion_mes, max_sit_mes_con_garantia, max_sit_mes_sin_garantia, 
                   peor_situacion_respuesta, mora_mayor_30_dias, default), as.factor))

# Verificamos la estructura del dataset despu√©s de las conversiones
str(df_datos)


# Recodificamos Tipo_persona

df_datos <- df_datos %>%
  mutate(
    sexo_cat = case_when(
      tipo_persona == 20 ~ "Hombre",
      tipo_persona == 27 ~ "Mujer",
      tipo_persona %in% c(23, 24) ~ "Desconocido"
    ),
    sexo_num = case_when(
      tipo_persona == 20 ~ 0,  # Hombre ‚Üí 0
      tipo_persona == 27 ~ 1,  # Mujer ‚Üí 1
      tipo_persona %in% c(23, 24) ~ 2  # Desconocido ‚Üí 2
    )
  )


# Eliminar la columna id_individuo
df_datos <- df_datos %>%
  select(-id_individuo)

# Hacemos un an√°lisis exploratorio inicial de las variables
gt_plt_summary(df_datos, title="Figura 1. An√°lisis exploratorio inicial de las variables en conjunto excluyendo deudas mayores a 100000")

skimr::skim(df_datos)

# Vemos las columnas con datos nulos o faltantes
columnas_con_nulos <- df_datos %>%
    summarise_all(~ sum(is.na(.))) %>%
    pivot_longer(cols = everything(), names_to = "columna", values_to = "num_nulos") %>%
    filter(num_nulos > 0)

knitr::kable(columnas_con_nulos)


#############################################################
# Creamos una nueva categor√≠a [0: No aplica] para la variable max_sit_mes_con_garantia para aquellos 
# registros que no tienen deuda con garant√≠a y tienen valor NA
#############################################################


# Asignamos 0 a max_sit_mes_con_garantia si deuda_con_garantia_actual es 0 y max_sit_mes_con_garantia es NA
df_datos <- df_datos %>%
    mutate(max_sit_mes_con_garantia = ifelse(is.na(max_sit_mes_con_garantia) & deuda_con_garantia_actual == 0, 0, max_sit_mes_con_garantia))

# Volver a ver las columnas con datos nulos o faltantes
columnas_con_nulos <- df_datos %>%
    summarise_all(~ sum(is.na(.))) %>%
    pivot_longer(cols = everything(), names_to = "columna", values_to = "num_nulos") %>%
    filter(num_nulos > 0)

knitr::kable(columnas_con_nulos)

# Filtramos y seleccionamos las columnas deseadas para registros con max_sit_mes_sin_garantia = NA
registros_con_na <- df_datos %>%
    filter(is.na(max_sit_mes_sin_garantia)) %>%
    select(deuda_total_actual, deuda_con_garantia_actual, prop_con_garantia_actual, tiene_garantia_actual, max_sit_mes_sin_garantia)

# Verificamos los registros filtrados
knitr::kable(registros_con_na)

# Asignamos 0 a max_sit_mes_sin_garantia si prop_con_garantia_actual es 1 y max_sit_mes_sin_garantia es NA
df_datos <- df_datos %>%
    mutate(max_sit_mes_sin_garantia = ifelse(is.na(max_sit_mes_sin_garantia) & prop_con_garantia_actual == 1, 0, max_sit_mes_sin_garantia))

# Volver a ver las columnas con datos nulos o faltantes
columnas_con_nulos <- df_datos %>%
    summarise_all(~ sum(is.na(.))) %>%
    pivot_longer(cols = everything(), names_to = "columna", values_to = "num_nulos") %>%
    filter(num_nulos > 0)

knitr::kable(columnas_con_nulos)


#
# Aca puedo verificar que ya no tengo valores nulos
#



#############################################################
# Cita de c√≥digo
## Licencia: desconocida
## Autor: Arena, Cristian
## Actualizaci√≥n: Ajuste con par√°metros de corte y coeficientes propios
#############################################################


# Funci√≥n para calcular el rango de edad
calcular_rango_edad_2019 <- function(proxy_edad_actual) {
  if (is.na(proxy_edad_actual)) {
    return(NA)
  }
  
  # Calculamos a√±o de nacimiento
  if (proxy_edad_actual >= 500) {
    anio_nacimiento <- 2010 + floor((proxy_edad_actual - 500)/10)
  } else if (proxy_edad_actual >= 424) {
    anio_nacimiento <- 2000 + floor((proxy_edad_actual - 424)/7.6)
  } else if (proxy_edad_actual >= 284) {
    anio_nacimiento <- 1980 + floor((proxy_edad_actual - 284)/7)
  } else if (proxy_edad_actual >= 217) {
    anio_nacimiento <- 1970 + floor((proxy_edad_actual - 217)/6.7)
  } else if (proxy_edad_actual >= 142) {
    anio_nacimiento <- 1960 + floor((proxy_edad_actual - 142)/7.5)
  } else if (proxy_edad_actual >= 45) {
    anio_nacimiento <- 1940 + floor((proxy_edad_actual - 45)/4.85)
  } else {
    anio_nacimiento <- 1920 + floor((proxy_edad_actual - 20) / 1.25)
  }
  
  # Calculamos edad en 2019
  edad_2019 <- 2019 - anio_nacimiento
  
  # Asignamos rango de edad
  if (edad_2019 < 20) {
    rango_edad <- "<20"
  } else if (edad_2019 <= 30) {
    rango_edad <- "20-29"
  } else if (edad_2019 <= 40) {
    rango_edad <- "30-39"
  } else if (edad_2019 <= 50) {
    rango_edad <- "40-49"
  } else if (edad_2019 <= 60) {
    rango_edad <- "50-60"
  } else {
    rango_edad <- ">60"
  }
  
  return(rango_edad)
}

# Creamos nueva columna con rango de edad calculado para cada individuo
#df_datos$rango_edad_2019 <- sapply(df_datos$proxy_edad_actual, calcular_rango_edad_2019)

df_datos <- df_datos %>%
  mutate(rango_edad_2019 = map(proxy_edad_actual, calcular_rango_edad_2019) %>% unlist())

# Mostramos un resumen de los resultados
print("Resumen de rangos de edad al 2019:")
knitr::kable(table(df_datos$rango_edad_2019))

# Mostramos algunas filas de ejemplo
print("Ejemplos de registros con el rango de edad al 2019:")
knitr::kable(head(df_datos[, c("proxy_edad_actual", "rango_edad_2019")]))


df_datos <- df_datos %>%
  mutate(
    cat_edad = case_when(
      rango_edad_2019 == "<20"    ~ 0,
      rango_edad_2019 == "20-29"  ~ 1,
      rango_edad_2019 == "30-39"  ~ 2,
      rango_edad_2019 == "40-49"  ~ 3,
      rango_edad_2019 == "50-60"  ~ 4,
      TRUE                        ~ 5  # Cualquier otro valor
    )
  )


# Aseguramos que la columna rango_edad_2019 sea de tipo categ√≥rico
df_datos <- df_datos %>%
    mutate(rango_edad_2019 = as.factor(rango_edad_2019),
           sexo_cat = as.factor(sexo_cat)
           )


```

### Seleccionamos el conjunto de datos para trabajar

```{r}

#############################################################
#
# Verificamos la cantidad de registros que no cumplen la condici√≥n del enunciado
#
#    Con respecto al trabajo final les quer√≠amos avisar que si bien en el
#    enunciado dice que la muestra utilizada est√° compuesta por cuits cuyo 
#    "monto total adeudado en ese momento no superaba los 100.000 pesos 
#    argentinos.", en la base quedaron algunos casos (1705) que s√≠ tienen 
#    deuda total en junio 2019 mayor a 100.000.
# 
#############################################################

cant <- sum(df_datos$deuda_total_actual > 100, na.rm = TRUE)
print(paste("Cantidad de registros estrictamente mayores a 100:", cant))

cant <- sum(df_datos$deuda_total_actual >= 100, na.rm = TRUE)
print(paste("Cantidad de registros mayores o iguales a 100:", cant))

#############################################################
# Y porque los n√∫meros est√°n redondeados a miles, voy a filtrar los valores
# mayores o iguales a 100 en el campo deuda_total_actual, luego de 
# verificar que a esa condici√≥n 1705 registros la cumplen.
#############################################################

# Filtramos filas con deuda_total_actual mayor a 100
filas_con_deuda_mayor_100 <- df_datos %>%
    filter(deuda_total_actual >= 100)

# Excluir registros con deuda_total_actual mayor a 100
df_seleccionados <- df_datos %>%
    filter(deuda_total_actual < 100)

# Vemos las filas con deuda_total_actual mayor a 100
knitr::kable(filas_con_deuda_mayor_100)


```

## Comenzamos el analisis exploratorio

```{r}


# Hacemos un an√°lisis exploratorio inicial de las variables
#gt_plt_summary(df_seleccionados, title="Figura 2. An√°lisis exploratorio inicial de las variables en conjunto excluyendo deudas mayores a 100000, sin valores nulos")


```

## An√°lisis univariado

```{r}

df2 <- pastecs::stat.desc(df_seleccionados) %>% as.matrix %>% as.data.frame %>% round(2)

df2 <- format(df2, scientific = FALSE)

df2 <- df2 %>%
    select_if(is.numeric)

knitr::kable(t(data.frame(df2)), digits = 2)

# Utilizamos la funci√≥n skim para describir la distribuci√≥n univariada de cada columna
skimr::skim(df_seleccionados)


```

## Hacemos graficos de distribucion

```{r}

#############################################################
# Calculamos el n√∫mero √≥ptimo de bins (intervalos) para el histograma utilizando 
# la regla de Freedman-Diaconis a trav√©s de la funci√≥n nclass.FD del paquete MASS

# La Regla de Freedman-Diaconis es un m√©todo para determinar el tama√±o √≥ptimo de 
# los bins (intervalos) en un histograma. Busca un balance entre precisi√≥n y suavidad
# en la distribuci√≥n de los datos, evitando histogramas con demasiados o muy pocos bins.

# F√≥rmula de Freedman-Diaconis
# Bin width=2√óIQRn1/3
# Bin width=2√ón1/3IQR‚Äã

# Donde:

#    IQR = Rango intercuart√≠lico (diferencia entre el cuartil 3 y el cuartil 1).
#    n = N√∫mero total de observaciones (tama√±o de la muestra).
#    Bin width = Ancho del intervalo del histograma.

# üìå ¬øPor qu√© se usa el IQR?

#    Es robusto frente a valores at√≠picos (outliers).
#    Proporciona una mejor representaci√≥n de la dispersi√≥n de los datos que la
#    desviaci√≥n est√°ndar.
#############################################################


# Funci√≥n para crear gr√°ficos de distribuci√≥n
plot_distribution <- function(data, column) {
  if (is.numeric(data[[column]])) {
    # Calculamos el n√∫mero √≥ptimo de bins usando la regla de Freedman-Diaconis
    num_bins <- nclass.FD(data[[column]])
    ggplot(data, aes(x = .data[[column]])) +
      geom_histogram(bins = num_bins, fill = "blue", color = "black") +
      labs(title = paste("Distribuci√≥n de", column), x = column, y = "Frecuencia") +
      theme_minimal()
  } else if (is.factor(data[[column]])) {
    ggplot(data, aes(x = .data[[column]])) +
      geom_bar(fill = "blue", color = "black") +
      labs(title = paste("Distribuci√≥n de", column), x = column, y = "Frecuencia") +
      theme_minimal()
  }
}

# Creamos una lista de gr√°ficos de distribuci√≥n para cada columna
plots <- map(colnames(df_seleccionados), ~ plot_distribution(df_seleccionados, .x))


# Presentamos los gr√°ficos en una matriz
do.call(grid.arrange, c(plots, ncol = 6))




# Funci√≥n para crear boxplots
plot_boxplot <- function(data, column) {
  ggplot(data, aes(y = .data[[column]])) +
    geom_boxplot(fill = "blue", color = "black") +
    labs(title = paste("Boxplot de", column), y = column) +
    theme_minimal()
}

# Creamos una lista de gr√°ficos de boxplot para cada columna num√©rica
boxplots <- map(names(df_seleccionados), ~ {
  if (is.numeric(df_seleccionados[[.x]])) {
    plot_boxplot(df_seleccionados, .x)
  } else {
    NULL
  }
}) %>% compact()

# Presentamos los gr√°ficos en una matriz
do.call(grid.arrange, c(boxplots, ncol = 6))



```

## Deteccion de Outliers

```{r}

# Outliers

# Funci√≥n para identificar outliers usando el IQR
identify_outliers <- function(data, column) {
  Q1 <- quantile(data[[column]], 0.25, na.rm = TRUE)
  Q3 <- quantile(data[[column]], 0.75, na.rm = TRUE)
  IQR <- Q3 - Q1
  lower_bound <- Q1 - 1.5 * IQR
  upper_bound <- Q3 + 1.5 * IQR
  outliers <- data %>%
    filter(.data[[column]] < lower_bound | .data[[column]] > upper_bound)
  return(outliers)
}

# Identificamos outliers para cada columna num√©rica
outliers_list <- map(names(df_seleccionados), ~ {
  if (is.numeric(df_seleccionados[[.x]])) {
    outliers <- identify_outliers(df_seleccionados, .x)
    if (nrow(outliers) > 0) {
      return(list(column = .x, outliers = outliers))
    }
  }
  return(NULL)
}) %>% compact()

# Mostramos los outliers identificados
walk(outliers_list, ~ {
  cat("Outliers en la columna:", .x$column, "\n")
  print(.x$outliers)
  cat("\n")
})

```

## Correlaciones

```{r}

# Correlaciones


#############################################################
# Eliminamos las columnas categoricas no ordinales y hacer ordinales aquellas 
# que puedan serlo
#############################################################


# Filtramos las columnas num√©ricas del DataFrame
col_numericas <- df_seleccionados %>%
  select_if(is.numeric)

# Calculamos la matriz de correlaciones
matriz_corr <- cor(col_numericas, use = "complete.obs")

# Mostramos la matriz de correlaciones
print(matriz_corr)

# Visualizamos la matriz de correlaciones
corrplot(matriz_corr, method = "color", type = "upper", 
        tl.col = "black", tl.srt = 45, addCoef.col = "black")

#
# Correlaciones 2 
#

# Guardamos el gr√°fico en un archivo PNG
png("pairs_panels.png", width = 1200, height = 1200)
par(mar = c(2, 2, 2, 2))
options(repr.plot.width = 10, repr.plot.height = 8)  # Ajusta el ancho y alto

# Creamos el gr√°fico de pares
pairs.panels(
  col_numericas,
  method = "pearson",  # correlation
  hist.col = "#00AFBB",
  density = TRUE,      # show density
  ellipses = T     # show correlation ellipses
)

# Cerramos el dispositivo PNG
dev.off()

# Correlaciones 3

library(GGally)
ggpairs(col_numericas)  # Gr√°fico de pares alternativo


```

## Correlaciones 2

```{r}

# Filtramos las columnas num√©ricas del DataFrame
col_numericas <- df_seleccionados %>%
  select(where(is.numeric))

# Calculamos la matriz de correlaciones
matriz_corr <- cor(col_numericas, use = "complete.obs")

# Mostramos la matriz de correlaciones
print(matriz_corr)

# Visualizamos la matriz de correlaciones
corrplot(matriz_corr, method = "color", type = "upper", 
        tl.col = "black", tl.srt = 45, addCoef.col = "black")

# Guardamos el gr√°fico en un archivo PNG
ggsave("pairs_panels.png", width = 12, height = 12, units = "in", dpi = 300)

# Creamos el gr√°fico de pares
pairs.panels(
  col_numericas,
  method = "pearson",  # correlation
  hist.col = "#00AFBB",
  density = TRUE,      # show density
  ellipses = FALSE     # show correlation ellipses
)

# Cerramos el dispositivo PNG
dev.off()

# Gr√°fico de pares alternativo
ggpairs(col_numericas)  # Gr√°fico de pares alternativo

```

## PCA

```{r}

# PCA

# Realizar el an√°lisis de componentes principales (PCA)
pca_result <- prcomp(col_numericas, scale. = TRUE)

# Resumen del PCA
summary(pca_result)

# Porcentaje de la variabilidad total explicada por las dos primeras componentes
var_explicada <- summary(pca_result)$importance[2, 1:2]
cat("Porcentaje de la variabilidad total explicada por las dos primeras componentes:\n")
print(var_explicada)

# Creamos un DataFrame con las componentes principales
pca_df <- as.data.frame(pca_result$x)

# A√±adimos la columna tipo_persona al DataFrame de PCA
pca_df <- pca_df %>%
  mutate(tipo_persona = df_seleccionados$tipo_persona)

# Visualizamos las dos primeras componentes principales
ggplot(pca_df, aes(x = PC1, y = PC2, color = tipo_persona)) +
  geom_point(alpha = 0.7) +
  labs(title = "PCA: Primeras dos componentes principales",
      x = "Componente Principal 1",
      y = "Componente Principal 2") +
  theme_minimal()

# Interpretaci√≥n de los componentes
cat("Cargas de las variables en las dos primeras componentes:\n")
print(pca_result$rotation[, 1:2])


```

## 

```{r}

```

## 

```{r}

```

## 

```{r}

```

## 

```{r}

```

## 

```{r}

```

## 

```{r}

```
